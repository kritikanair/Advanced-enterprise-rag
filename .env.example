# Advanced Multi-Source RAG - Environment Configuration

# ===== Vector Database Configuration =====
VECTOR_STORE=faiss
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
FAISS_INDEX_PATH=./data/faiss_index

# ===== LLM Configuration =====
# Open-Source Models (Choose one)
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
# Alternative options:
# LLM_MODEL=HuggingFaceH4/zephyr-7b-beta
# LLM_MODEL=meta-llama/Llama-2-7b-chat-hf
# LLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0  # Lightweight option

LLM_DEVICE=cpu  # or 'cuda' if GPU available
LLM_MAX_LENGTH=2048
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
LLM_LOAD_IN_4BIT=false  # Set to true for 4-bit quantization (saves memory)

# ===== Document Processing =====
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MIN_CHUNK_SIZE=100
MAX_CHUNK_SIZE=1024

# ===== Retrieval Configuration =====
TOP_K_RETRIEVERS=5
RERANK_TOP_K=3
SIMILARITY_THRESHOLD=0.5

# ===== Graph Database =====
GRAPH_ENABLE=true
NER_MODEL=en_core_web_sm  # spaCy model
MAX_GRAPH_NODES=1000
MAX_GRAPH_EDGES=5000

# ===== Sentence Window Configuration =====
SENTENCE_WINDOW_SIZE=3  # Context sentences before/after
ENABLE_SENTENCE_WINDOW=true

# ===== Re-ranking =====
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
ENABLE_RERANKING=true

# ===== Application Settings =====
APP_NAME=Advanced Multi-Source RAG
APP_PORT=8501
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log

# ===== Data Storage =====
DATA_DIR=./data
MODELS_DIR=./models
DOCUMENTS_DIR=./data/documents
CACHE_DIR=./data/cache

# ===== Performance =====
MAX_WORKERS=4  # For parallel processing
CACHE_EMBEDDINGS=true
BATCH_SIZE=32

# ===== UI Configuration =====
STREAMLIT_THEME=light
SHOW_METRICS=true
SHOW_SOURCE_DOCS=true
MAX_UPLOAD_SIZE_MB=200
